{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcTFVkXSUVNmlbQ6F4zRKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaurynasRekasius/colab_test/blob/main/%5BOCT_05%5D_YouTube_Episode_List.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "HZ24uM_ZNFeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api\n",
        "!pip install isodate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OV1CIGOYMuK",
        "outputId": "79d7ee59-23dd-403d-a9f5-204a27c55572"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yvouatNJLq4E"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api._errors import NoTranscriptFound\n",
        "\n",
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.errors import HttpError\n",
        "from googleapiclient.discovery import build\n",
        "import googleapiclient.discovery\n",
        "\n",
        "import datetime\n",
        "import requests\n",
        "import isodate\n",
        "import json\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "MAX_API_RETRIES = 3\n",
        "DELAY_BETWEEN_RETRIES = 10\n",
        "RATE_LIMIT_DELAY = 60\n",
        "\n",
        "DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
        "\n",
        "NUM_EPISODES_TO_FETCH = 5\n",
        "MIN_VIDEO_DURATION = datetime.timedelta(minutes=30)"
      ],
      "metadata": {
        "id": "haI5t8IYNB6q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YouTube API setup\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "# API key\n",
        "youtube_api_key = \"AIzaSyD3VSe0NXgATmIpWGlB1DJGFTvUZt9Lhhc\"\n",
        "# API client\n",
        "youtube = googleapiclient.discovery.build(\n",
        "   api_service_name, api_version, developerKey = youtube_api_key)\n",
        "\n"
      ],
      "metadata": {
        "id": "rI2JIgV2M_vY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Sheets API setup\n",
        "\n",
        "#chnops account\n",
        "json_str=r\"\"\"\n",
        "{\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"compact-sylph-248418\",\n",
        "  \"private_key_id\": \"1c6753bac83ac304a86e6ed2d0fa0e70d6459aaa\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQD9keJsI0nPWm7A\\nY4BAlwZqY8iS0A+H8Hh0JoYxHyb/F23yWqFB/MjAbfz8yAqg0C3zde3HPJagm7if\\n6JR8df0HrPUbVR+SuP67cDXYfeTYkZj/q9V8e1uiVmp7en7h2I6tXVWNWStPH026\\n01amjSx03Y4a4S6gtMf5bRhYV6HCeyfQiLGZzo+LEWrcq/w73BWO8lgrWKvDvsoq\\nKJdbQNQIefTLUeWvKIExhMTMdIa9bHxqifEW0Xf6d3U1FsTTog9hg0UsKezFCaUA\\nEM1fGC3lMLetf9k3B4WroRve6/lSQH0TU8agjCZO41EBjdfN5xD+SD62aZbR9Xlv\\nm1UcpZenAgMBAAECggEAUUo9flFpzjG9o6vCZ/KCugS3Pmm5MOlklEftaT4FcG4A\\nb1uiqtbxPM+F9TvkPF3A/XXm/qJr351MeOdFAwmITreh9Fs7vfvUnh6BBKCHhu5W\\nUFC0Ji4d2FM/28oPdzPHuchcLu5RNhJhBu3Nr6M+h1Cnx/I80oRiP5I75cZiM0hI\\nxMFSn74VgohRTpxT3ovDLnmBpeiNHaIDCHkYxutQKWfKKMymiPLt5fiN9F89xwJ0\\nYJKIVV3eWbVyDeDA1IZaLNVoXO0xa9xnq2nh2sLgjOih0Ig84riPxZsnAi9nsdC1\\nrgkbK2rxxddd96ykLntT37VoBdsEsMgKYZ6dlGLscQKBgQD//3Nne2U39BpGWWLo\\npln4MJRli3qUCp1lPItY8n8D6K38m7LqhND/0R9eC4ZWL4J9np+/4rmh7wuzK4DI\\n3qliFiGgNRjD8vwb0iyr7cunGAH5VFAD9l1e5kpRk19WgMNoZBIxK5TlW5kobPNL\\nh2INZr7SeCTPmTlzEWwsPT9e3QKBgQD9km2vSY+cczF8G/z9UvwDdgus4vQ1In1h\\nY4L1WYZvox+u+SuG+iuOn1xo9b+kc7CWrZzVNd6ezfCGafTxY7D5Sbq5Ye6Zd5iR\\nlsIFwEuiH0S9gXHCWsuaxFQgYC9mfUNhXah03mLg7PCUQYVr5jfIgg1DpyRDSdU1\\nZ6bY55TOUwKBgBP64QvzkovSbnaNJW4ZBa6cRAjE4RVK2sv69LlFe+pXL7UmhclO\\nAm3k6XjSl3KElL+vMLKuRGTCHnymaY/D6R5xscAqRLuObGTTe48TqTBqbEUEcpZM\\nlS8B9Ez3nppGxHmSTeUujJl2E7cXAcokT9/R5BTTMbRONjCn7HRrd1W1AoGBAOp4\\nU+QZ6SmJeuCAINc9vLqWlQUwdxAK7FT5Z0bnmV/xPoLU9GLDQTOIODL1yleOgmNR\\n9gtQ3KGLXDVuFIiA3kwk2PxCihZueC1ncdFPlqA6uZ1h7IcC3fImSIQHbM0gVwXZ\\nTMOEP3osnej5DR5QqpRFbW55RxbRVs0jIyy+NuLxAoGAGi7T/o6Wkk4l3g5nTHZ4\\nKXJifs03DvfVbVkIcXzHFayJxRdcOprUFVujA6R9p8uwp+EHcRF4AbCyaQTO/tA8\\njP7LJ2VRLuzk7Mnrd9PhITgOx1u45snJLebltgD3XFtayTjrnoZkJpn++ktV/QrU\\ndrfrthgfEQNj67JRXoEZCcU=\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"summary-app@compact-sylph-248418.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"115883690976457251380\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/summary-app%40compact-sylph-248418.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "json_obj = json.loads(json_str.replace(\"\\\\\\\\n\", \"\\\\n\"))\n",
        "\n",
        "# Set up credentials\n",
        "scope = ['https://www.googleapis.com/auth/spreadsheets',\n",
        "          'https://www.googleapis.com/auth/drive.file']\n",
        "credentials = Credentials.from_service_account_info(json_obj, scopes=scope)\n",
        "\n",
        "# Connect to Google Drive\n",
        "drive_service = build('drive', 'v3', credentials=credentials)\n",
        "sheets_service = build('sheets', 'v4', credentials=credentials)\n",
        "SHEET_RANGE = 'Sheet1'"
      ],
      "metadata": {
        "id": "xSLa6-wWM3dI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants for SHEET_ID_AU Column Names\n",
        "SHEET_ID_AU = '1GJEDiz0b6E96GlBLPoZTIGQhY4Js_sLbHSmTJ1mo9H4'\n",
        "\n",
        "AU_COL_AUTHOR = \"author\"\n",
        "AU_COL_URL = \"url\"\n",
        "AU_COL_CHANNEL_ID = \"channel_id\"\n",
        "AU_COL_LATEST_DATE = \"latest_date\"\n",
        "AU_COL_LATEST_URL = \"latest_url\"\n",
        "\n",
        "# Constants for SHEET_ID_EP Column Names\n",
        "SHEET_ID_EP = '1ZHX-rv04TIl0PUNKqH7LT5yJGVbkwmtPcGusIDFVsRo'\n",
        "\n",
        "EP_COL_SUMMARY_ID = \"summary_id\"\n",
        "EP_COL_DATE = \"date\"\n",
        "EP_COL_AUTHOR = \"author\"\n",
        "EP_COL_CHANNEL = \"channel\"\n",
        "EP_COL_TITLE = \"episode_title\"\n",
        "EP_COL_URL = \"url\"\n",
        "\n",
        "# Constants for SHEET_ID_VAR\n",
        "SHEET_ID_VAR = '1qWAV1NEPH_xwWCtu7D_-4PV5a3e8XZSb_UXXX1OnvPc'\n",
        "\n",
        "VAR_COL_RECENT_SUMMARY_ID = \"recent_summary_id\""
      ],
      "metadata": {
        "id": "XLj31ConhuNO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "Dyt00hHzNQ-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_api_call_with_retries(func, *args, **kwargs):\n",
        "    \"\"\"A helper function to make an API call with specified retries and delay.\"\"\"\n",
        "    for retry in range(MAX_API_RETRIES):\n",
        "        try:\n",
        "            return func(*args, **kwargs).execute()  # Adding .execute() here\n",
        "        except HttpError as e:\n",
        "            err_content = e.content.decode('utf-8')\n",
        "            print(f\"HTTP Error content: {err_content}\")\n",
        "            if \"quota\" in err_content.lower():\n",
        "                print(f\"Quota exceeded. Waiting for {RATE_LIMIT_DELAY} seconds and then retrying... [{retry + 1}/{MAX_API_RETRIES}]\")\n",
        "                time.sleep(RATE_LIMIT_DELAY)\n",
        "            else:\n",
        "                print(f\"Error: {e}. Waiting for {DELAY_BETWEEN_RETRIES} seconds and then retrying... [{retry + 1}/{MAX_API_RETRIES}]\")\n",
        "                time.sleep(DELAY_BETWEEN_RETRIES)\n",
        "        except Exception as e:\n",
        "            print(f\"Other error: {e}. Waiting for {DELAY_BETWEEN_RETRIES} seconds and then retrying... [{retry + 1}/{MAX_API_RETRIES}]\")\n",
        "            time.sleep(DELAY_BETWEEN_RETRIES)\n",
        "    raise Exception(f\"Failed to make API call after {MAX_API_RETRIES} retries.\")"
      ],
      "metadata": {
        "id": "iSPdsqFkSCnF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_column_indices(sheet_id, column_names):\n",
        "    \"\"\"Fetch the header row from the given sheet and return a dictionary mapping column names to their indices.\"\"\"\n",
        "    header = make_api_call_with_retries(sheets_service.spreadsheets().values().get, spreadsheetId=sheet_id, range=\"A1:Z1\").execute().get('values', [])[0]\n",
        "    return {col: header.index(col) for col in column_names}\n",
        "\n",
        "def col_index_to_letter(index):\n",
        "    \"\"\"Convert a column index into its corresponding letter.\"\"\"\n",
        "    letters = []\n",
        "    while index >= 0:\n",
        "        letters.append(chr(index % 26 + ord('A')))\n",
        "        index = index // 26 - 1\n",
        "    return ''.join(reversed(letters))"
      ],
      "metadata": {
        "id": "oVPiPNNUKYTS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_or_fetch_channel_id(channel, youtube_api_key, channels):\n",
        "    \"\"\"Retrieve the channel ID from the sheet or fetch it using the YouTube API.\"\"\"\n",
        "    if channel[AU_COL_INDICES[AU_COL_CHANNEL_ID]]:\n",
        "        return channel[AU_COL_INDICES[AU_COL_CHANNEL_ID]]\n",
        "    else:\n",
        "        # Extract channel username from URL\n",
        "        channel_url = channel[AU_COL_INDICES[AU_COL_URL]]\n",
        "        username = channel_url.split(\"@\")[-1]\n",
        "\n",
        "        # Send a request to the YouTube Data API to search for the channel using the username\n",
        "        response = requests.get(\n",
        "            f\"https://www.googleapis.com/youtube/v3/search?part=snippet&type=channel&q={username}&key={youtube_api_key}\"\n",
        "        )\n",
        "\n",
        "        # Parse the response\n",
        "        data = json.loads(response.text)\n",
        "\n",
        "        # Check if any items were returned\n",
        "        if \"items\" in data and len(data[\"items\"]) > 0:\n",
        "            # Get the channel ID from the first result\n",
        "            channel_id = data[\"items\"][0][\"id\"][\"channelId\"]\n",
        "\n",
        "            # Update the sheet with the fetched channel ID\n",
        "            data = {\"values\": [[channel_id]]}\n",
        "            index = channels.index(channel) + 2  # +2 to account for 0-based index and header row\n",
        "            column_letter = col_index_to_letter(AU_COL_INDICES[AU_COL_CHANNEL_ID])\n",
        "            make_api_call_with_retries(\n",
        "                sheets_service.spreadsheets().values().update,\n",
        "                spreadsheetId=SHEET_ID_AU,\n",
        "                range=f\"{column_letter}{index}\",\n",
        "                valueInputOption=\"RAW\",\n",
        "                body=data\n",
        "            ).execute()\n",
        "            return channel_id\n",
        "        else:\n",
        "            raise Exception(f\"Could not fetch channel ID for URL: {channel[AU_COL_INDICES[AU_COL_URL]]}. No items returned.\")"
      ],
      "metadata": {
        "id": "iN_ULm2niAXu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_latest_summary_id(sheets_service):\n",
        "    \"\"\"Get the latest summary_id from SHEET_ID_VAR.\"\"\"\n",
        "    response = make_api_call_with_retries(sheets_service.spreadsheets().values().get, spreadsheetId=SHEET_ID_VAR, range=\"sheet1!A2:A2\")\n",
        "    summary_id_value = response.get('values', [])[0][0]\n",
        "\n",
        "    # Extract the numeric part and return the value\n",
        "    latest_id = int(summary_id_value.replace('id', ''))\n",
        "\n",
        "    return latest_id"
      ],
      "metadata": {
        "id": "hjyKAGAWKUUV"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_new_episodes(channel_url, author_name, youtube):\n",
        "    # Extract channel_id from URL\n",
        "    channel_id = channel_url.split(\"@\")[-1]\n",
        "    response = make_api_call_with_retries(youtube.search().list, part=\"snippet\", channelId=channel_id, order=\"date\", maxResults=NUM_EPISODES_TO_FETCH)\n",
        "\n",
        "    new_episodes = []\n",
        "    for item in response.get(\"items\", []):\n",
        "        # Check if the item is a video\n",
        "        if \"videoId\" in item.get(\"id\", {}):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "            video_title = item[\"snippet\"][\"title\"]\n",
        "            published_at = datetime.datetime.strptime(item[\"snippet\"][\"publishedAt\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "            # Check video duration\n",
        "            video_data = make_api_call_with_retries(youtube.videos().list, part=\"contentDetails\", id=video_id)\n",
        "            video_duration = isodate.parse_duration(video_data[\"items\"][0][\"contentDetails\"][\"duration\"])\n",
        "\n",
        "            if video_duration >= MIN_VIDEO_DURATION:\n",
        "                new_episodes.append({\n",
        "                    EP_COL_DATE: published_at.strftime(DATE_FORMAT),\n",
        "                    EP_COL_AUTHOR: author_name,  # Use the passed author_name\n",
        "                    EP_COL_CHANNEL: channel_url,  # Use the passed channel_url\n",
        "                    EP_COL_TITLE: video_title,\n",
        "                    EP_COL_URL: f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "                })\n",
        "    return new_episodes"
      ],
      "metadata": {
        "id": "x0HBAIZFVjUD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_episodes_to_sheet(episodes, sheets_service):\n",
        "    \"\"\"Append the new episodes to SHEET_ID_EP.\"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # Get the latest summary_id\n",
        "    latest_id = get_latest_summary_id(sheets_service)\n",
        "\n",
        "    # Fetch the header of SHEET_ID_EP to determine column positions\n",
        "    response = make_api_call_with_retries(\n",
        "        sheets_service.spreadsheets().values().get,\n",
        "        spreadsheetId=SHEET_ID_EP,\n",
        "        range=\"Sheet1!1:1\"\n",
        "    )\n",
        "    header = response.get('values', [])[0]\n",
        "\n",
        "    # Get column positions based on header\n",
        "    summary_id_index = header.index(EP_COL_SUMMARY_ID)\n",
        "    date_index = header.index(EP_COL_DATE)\n",
        "    author_index = header.index(EP_COL_AUTHOR)\n",
        "    channel_index = header.index(EP_COL_CHANNEL)\n",
        "    title_index = header.index(EP_COL_TITLE)\n",
        "    url_index = header.index(EP_COL_URL)\n",
        "\n",
        "    for episode in episodes:\n",
        "        # Increment the summary_id for each new episode\n",
        "        latest_id += 1\n",
        "        summary_id = f\"id{str(latest_id).zfill(6)}\"\n",
        "\n",
        "        # Create a row with all None values and then populate the required columns\n",
        "        row = [None] * len(header)\n",
        "        row[summary_id_index] = summary_id\n",
        "        row[date_index] = episode[EP_COL_DATE]\n",
        "        row[author_index] = episode[EP_COL_AUTHOR]\n",
        "        row[channel_index] = episode[EP_COL_CHANNEL]\n",
        "        row[title_index] = episode[EP_COL_TITLE]\n",
        "        row[url_index] = episode[EP_COL_URL]\n",
        "        rows.append(row)\n",
        "\n",
        "    # Append to the sheet\n",
        "    make_api_call_with_retries(\n",
        "        sheets_service.spreadsheets().values().append,\n",
        "        spreadsheetId=SHEET_ID_EP,\n",
        "        range=\"Sheet1\",\n",
        "        valueInputOption=\"RAW\",\n",
        "        body={\"values\": rows}\n",
        "    ).execute()"
      ],
      "metadata": {
        "id": "BuwOkGNuFLwh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_latest_episode_for_author(author, latest_date, latest_url, sheets_service):\n",
        "    \"\"\"Update the latest episode details for a given author in SHEET_ID_AU.\"\"\"\n",
        "    # Get header row from SHEET_ID_AU\n",
        "    response = make_api_call_with_retries(sheets_service.spreadsheets().values().get, spreadsheetId=SHEET_ID_AU, range=f\"{SHEET_RANGE}!1:1\")\n",
        "    headers = response.get('values', [])[0]\n",
        "\n",
        "    # Get column indices for required columns based on their names\n",
        "    author_index = headers.index(AU_COL_AUTHOR)\n",
        "    latest_date_index = headers.index(AU_COL_LATEST_DATE)\n",
        "    latest_url_index = headers.index(AU_COL_LATEST_URL)\n",
        "\n",
        "    # Prepare data to be written\n",
        "    date_str = latest_date.strftime(DATE_FORMAT)\n",
        "    data = {\"values\": [[date_str, latest_url]]}\n",
        "\n",
        "    # Find the author's row\n",
        "    response = make_api_call_with_retries(sheets_service.spreadsheets().values().get, spreadsheetId=SHEET_ID_AU, range=SHEET_RANGE)\n",
        "    for index, row in enumerate(response.get('values', [])):\n",
        "        if row[author_index] == author:\n",
        "            start_col = chr(65 + latest_date_index)  # Convert to A=1, B=2, etc.\n",
        "            end_col = chr(65 + latest_url_index)\n",
        "            make_api_call_with_retries(sheets_service.spreadsheets().values().update, spreadsheetId=SHEET_ID_AU, range=f\"{SHEET_RANGE}!{start_col}{index + 1}:{end_col}{index + 1}\", valueInputOption=\"RAW\", body=data)\n",
        "            break"
      ],
      "metadata": {
        "id": "fWFjvJXRN8yX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_sheet_with_new_episodes():\n",
        "    # Fetch channels from SHEET_ID_AU\n",
        "    response = make_api_call_with_retries(sheets_service.spreadsheets().values().get, spreadsheetId=SHEET_ID_AU, range=SHEET_RANGE)\n",
        "    channels = response.get('values', [])[1:]\n",
        "\n",
        "    all_new_episodes = []\n",
        "\n",
        "    for channel in channels:\n",
        "        channel_name = channel[AU_COL_INDICES[AU_COL_URL]]\n",
        "        author_name = channel[AU_COL_INDICES[AU_COL_AUTHOR]]\n",
        "        latest_episode_date_str = channel[AU_COL_INDICES[AU_COL_LATEST_DATE]]\n",
        "\n",
        "        # Convert to datetime object, if it's not the column name\n",
        "        latest_episode_date = datetime.datetime.strptime(latest_episode_date_str, DATE_FORMAT) if latest_episode_date_str != AU_COL_LATEST_DATE else None\n",
        "\n",
        "        # Fetch new episodes from the YouTube channel\n",
        "        new_episodes = fetch_new_episodes(channel_name, author_name, youtube)\n",
        "\n",
        "        if not new_episodes:\n",
        "            print(f\"No new episodes found for {author_name}.\")\n",
        "            continue\n",
        "\n",
        "        # Filter out episodes that are older than the latest episode for this author\n",
        "        if latest_episode_date:\n",
        "            new_episodes = [episode for episode in new_episodes if datetime.datetime.strptime(episode[EP_COL_DATE], DATE_FORMAT) > latest_episode_date]\n",
        "\n",
        "        # Update the latest episode details for this author in SHEET_ID_AU\n",
        "        latest_episode = new_episodes[0]  # The episodes are already sorted by date\n",
        "        update_latest_episode_for_author(author_name, datetime.datetime.strptime(latest_episode[EP_COL_DATE], DATE_FORMAT), latest_episode[EP_COL_URL], sheets_service)\n",
        "\n",
        "        all_new_episodes.extend(new_episodes)\n",
        "\n",
        "    # Add these episodes to SHEET_ID_EP\n",
        "    if all_new_episodes:\n",
        "        add_episodes_to_sheet(all_new_episodes, sheets_service)\n",
        "\n",
        "    print(\"Done!\")"
      ],
      "metadata": {
        "id": "Ok1D29jUFHTG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "3CshBFhMYQAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting indices for SHEET_ID_AU columns\n",
        "AU_COLS = [AU_COL_AUTHOR, AU_COL_URL, AU_COL_CHANNEL_ID, AU_COL_LATEST_DATE, AU_COL_LATEST_URL]\n",
        "AU_COL_INDICES = get_column_indices(SHEET_ID_AU, AU_COLS)\n",
        "\n",
        "\n",
        "# Getting indices for SHEET_ID_EP columns\n",
        "EP_COLS = [EP_COL_SUMMARY_ID, EP_COL_DATE, EP_COL_AUTHOR, EP_COL_CHANNEL, EP_COL_TITLE, EP_COL_URL]\n",
        "EP_COL_INDICES = get_column_indices(SHEET_ID_EP, EP_COLS)\n",
        "\n",
        "# Getting indices for SHEET_ID_VAR columns (if you need them)\n",
        "VAR_COLS = [VAR_COL_RECENT_SUMMARY_ID]\n",
        "VAR_COL_INDICES = get_column_indices(SHEET_ID_VAR, VAR_COLS)"
      ],
      "metadata": {
        "id": "fk8VwPJom3Lt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function\n",
        "update_sheet_with_new_episodes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lndVXwCSSD_C",
        "outputId": "3598deea-37e6-48b3-da57-fcaabaa22066"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Error content: {\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"Request contains an invalid argument.\",\n",
            "    \"errors\": [\n",
            "      {\n",
            "        \"message\": \"Request contains an invalid argument.\",\n",
            "        \"domain\": \"global\",\n",
            "        \"reason\": \"badRequest\"\n",
            "      }\n",
            "    ],\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Error: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/search?part=snippet&channelId=TheDiaryOfACEO&order=date&maxResults=5&key=AIzaSyD3VSe0NXgATmIpWGlB1DJGFTvUZt9Lhhc&alt=json returned \"Request contains an invalid argument.\". Details: \"[{'message': 'Request contains an invalid argument.', 'domain': 'global', 'reason': 'badRequest'}]\">. Waiting for 10 seconds and then retrying... [1/3]\n",
            "HTTP Error content: {\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"Request contains an invalid argument.\",\n",
            "    \"errors\": [\n",
            "      {\n",
            "        \"message\": \"Request contains an invalid argument.\",\n",
            "        \"domain\": \"global\",\n",
            "        \"reason\": \"badRequest\"\n",
            "      }\n",
            "    ],\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Error: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/search?part=snippet&channelId=TheDiaryOfACEO&order=date&maxResults=5&key=AIzaSyD3VSe0NXgATmIpWGlB1DJGFTvUZt9Lhhc&alt=json returned \"Request contains an invalid argument.\". Details: \"[{'message': 'Request contains an invalid argument.', 'domain': 'global', 'reason': 'badRequest'}]\">. Waiting for 10 seconds and then retrying... [2/3]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-33bddf9c0b9c>\u001b[0m in \u001b[0;36mmake_api_call_with_retries\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adding .execute() here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://youtube.googleapis.com/youtube/v3/search?part=snippet&channelId=TheDiaryOfACEO&order=date&maxResults=5&key=AIzaSyD3VSe0NXgATmIpWGlB1DJGFTvUZt9Lhhc&alt=json returned \"Request contains an invalid argument.\". Details: \"[{'message': 'Request contains an invalid argument.', 'domain': 'global', 'reason': 'badRequest'}]\">",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-4b64592510f7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mupdate_sheet_with_new_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-bcce80197863>\u001b[0m in \u001b[0;36mupdate_sheet_with_new_episodes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Fetch new episodes from the YouTube channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnew_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_new_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myoutube\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnew_episodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-b8e7c724bcf2>\u001b[0m in \u001b[0;36mfetch_new_episodes\u001b[0;34m(channel_url, author_name, youtube)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Extract channel_id from URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mchannel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"@\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_api_call_with_retries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myoutube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"snippet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannelId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxResults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPISODES_TO_FETCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnew_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-33bddf9c0b9c>\u001b[0m in \u001b[0;36mmake_api_call_with_retries\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: {e}. Waiting for {DELAY_BETWEEN_RETRIES} seconds and then retrying... [{retry + 1}/{MAX_API_RETRIES}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDELAY_BETWEEN_RETRIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Other error: {e}. Waiting for {DELAY_BETWEEN_RETRIES} seconds and then retrying... [{retry + 1}/{MAX_API_RETRIES}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}